---
title: "Supplementary material"
author: "Alexey Uvarovskii, Christoph Dieterich"
date: '`r Sys.Date()`'
output:
  pdf_document:
    highlight: default
    toc: yes
    toc_depth: 3
    number_sections: true
  github_document: default
mainfont: Helvetica
fontsize: 12pt
urlcolor: cyan
---

# Introduction

The aim of this document is to validate  the 
 pulseR package using simulated data.
First, we introduce the modelled system and how we simulate the read counts.
Next, we explain how one applies `pulseR` to this data.
We validate the performance of the package by comparison of the 
parameter estimations with their true values used in simulation.

## Kinetic model

We consider a pulse-experiment with no spike-ins added.
In this scheme, a labelled 4sU molecules are introduced to the medium and 
they are being incorporated in the nascent RNA.
Using pull down procedure, it is possible to get label-enriched fraction 
in order to quantify the kinetics rates of for the individual genes.
We consider that all three fractions (total, labelled, unlabelled)
are being sequenced and 
read counts are available for every gene under consideration.
Let us assume to have 2 replicates for 4 different time points, i.e.
in total there $2\times 4\times 3=24$ samples.

```{r}
library(pulseR)

set.seed(259)

nGenes <- 500
nReplicates <- 2
nTime <- 4


```

In the beginning of the experiment, the amount of the labelled RNA is zero and
the unlabelled RNA equals the steady state amount $\mu$.
The labelled RNA is being
synthesised with the rate $s$, and it degrades with the rate $d$.
We assume that  unlabelled one only degrades with the same rate $d$.\

The following system of ordinary differential equations describes this processes:
\begin{equation}
\begin{aligned}
\frac{d\text{[labelled RNA]}}{dt} &= s - d \text{[labelled RNA]}\\
\frac{d\text{[unlabelled RNA]}}{dt} &= -d \text{[unlabelled RNA]}\\
\text{[total RNA]} &= \text{[labelled RNA]} + \text{[unlabelled RNA]}
\end{aligned}
\label{eq:model}
\end{equation}
For constant rates of degradation $d$ and synthesis $s$, the amounts of RNA 
at time $t$ are
$$ 
\begin{aligned}
 \text{[total RNA]} &= \frac{s}{d} \equiv \mu \\
\text{[labelled RNA]} &= \mu (1 - e^{-dt})  \\
 \text{[unlabelled RNA]} &= \mu e^{-dt}.
\end{aligned}
$$


## Measured quantities

In reality, there are no pure labelled or unlabelled fractions in samples.
That is why it may be important to model fraction cross-contamination.
Here we assume that the labelled fraction consists of certain amount of
the unlabelled one, and, vice versa, the unlabelled one is contaminated
with the labelled molecules.
Hence, we distinguish the number of labelled reads and the number of reads
in the "labelled" fraction for a given gene.
We will use *fraction* to refer to the model accounting for cross-contamination:

\begin{equation}
\begin{aligned}
 \text{[total fraction]} &= \mu \\
\text{[pull down]} &= \alpha_1 \text{[labelled RNA]} +
\alpha_2 \text{[unlabelled RNA]}\\
\text{[flow through]} &= \alpha_3 \text{[unlabelled RNA]} +
\alpha_4 \text{[labelled RNA]}
\end{aligned}
\label{eq:contamination}
\end{equation}



# Model definition in pulseR

One can simulate count data using the function
`generateTestDataFrom`. This function takes as an input
formulas for the mean read counts, a condition matrix 
(e.g. condition $\times$ time), normalisation factors and the parameter values
used in the formulas.

## Formulas 

It is possible to generate formulas using the functions `growFrom0`, `grow`,
`amount` and `degrade`, which represent the simplest cases of the 
concentration kinetics:
```{r}
formulas <- list(
  total      = amount("mu"),
  labelled   = growFrom0("mu", "d", "time"),
  unlabelled = degrade("mu", "d", "time")
)
```

Alternatively, one can provide the expressions for the means explicitly:
```{r}

formulas2 <- MeanFormulas(
  total        = mu,
  labelled     = mu * (1 - exp(-d*time)),
  unlabelled   = mu * exp(-d*time)
)
identical(formulas, formulas2)
```

## Fractions

According to the introduced terms for fractions, we need to provide
the types of measured values, i.e. taking into account contamination
of pull down and flow through fractions:
```{r}
# important: the labels must be the same as in formulas,
# or they must be integer indexes
formulaIndexes <- list(
  total_fraction = 'total',
  pull_down      = c('labelled', 'unlabelled'),
  flow_through   = c('unlabelled', 'labelled')
)
```

The `formulaIndexes` list defines the linear relations for fractions
described by the 
eq.\ref{eq:contamination}.


## Conditions 

We specify the condition `data.frame`, which includes information about
the type of a  sample and the time point of its measurements:

```{r}
# create nReplicates * nTime * 3 (labelled, unlabelled, total) data points
conditions <- data.frame(
  condition = rep(names(formulaIndexes), each = nTime),
  time      = rep(1:nTime, length(formulaIndexes) * nReplicates))
rownames(conditions) <- paste0("sample_", seq_along(conditions$condition))
knitr::kable(conditions)
```

## Normalisation factors

Total amounts of labelled and unlabelled RNA are changing during the experiment.
It may affect the normalisation coefficients defined in eq.\ref{eq:contamination}.
That is why it is useful to introduce such coefficients for 
every time point, and, hence, 
we define samples groups depending on their measurement time and fraction.
Except the total fraction, other samples are considered to belong to different
group if the time points are different:
```{r}
fractions <- as.character(interaction(conditions))
# assume that the total RNA amount does not change with the time
# so all total fractions can be treated together
fractions[grep("total", fractions)] <- "total_fraction"
knitr::kable(cbind(rownames(conditions),fractions))
```

We use the internal package function  `pulseR:::addKnownToFormulas` in order 
to get the correct form of the list with the normalisation factors.
```{r}
known <- pulseR:::addKnownToFormulas(formulas, formulaIndexes, conditions)
normFactors <- known$formulaIndexes[unique(names(known$formulaIndexes))]
# the total fractions have the reference factor = 1
normFactors <- normFactors[-grep("total", names(normFactors))]
normFactors <- c(list(total_fraction = 1), normFactors)
# linear combinations with the coefficient 0.1 for contaminating fraction
# and the coefficient 3 for the main fraction of the sample
normFactors <- relist(c(1, rep(3, length(unlist(normFactors)) - 1)),
                      normFactors)
normFactors[-1] <- lapply(normFactors[-1], '[[<-',2,.10)
str(normFactors)
```

## Simulation

First, we define the true parameter values, on the basis of which 
we will generate the read counts matrix.
We sample the mean expression level and the degradation rates from 
finite intervals:
```{r}
# set size factor for the rnbinom function
par <- list(size = 1e2)
# set mean read number for every gene 
# by sampling from the log-uniform distribution
par$mu <- exp(runif(nGenes, 0, log(1e5)))
# set the degradation rates from log-uniform distribution
par$d <- exp(runif(nGenes,log(0.01), log(2)))
```
Now we have all the information in order to simulate the data 
from the negative binomial distribution
using the `generateTestDataFrom` function: 
```{r}
# the generateTestDataFrom needs for an input normFactors 
# provided for every individual sample (i.e. we need to utilise 
# the group information ourselves)
allNormFactors <- pulseR:::multiplyList(normFactors, fractions)

counts <- generateTestDataFrom(
  formulas, formulaIndexes, allNormFactors, par, conditions)
counts[1:5,1:10]
dim(counts)
```

# Fitting

Having generated data, we would like to investigate how well the true
parameter values for the model defined in eq.\ref{eq:model} 
can be recovered using the 
`pulseR` package.

This section describes a usual workflow for the analysis of the count data
originating from the spike-ins-free experiment  defined above.
This is an entry point of the package application to the real data.

## Create the PulseData object

The fitting procedure requires the definition of the model formulas, 
sample description and raw data as a single `PulseData` object.
We use previously defined objects, namely, the generated read counts,
the condition matrix, relations between formulas and samples.
In addition, we provide the information (`fractions`)
how to split the samples during the normalisation:
```{r}
pd <- PulseData(
  counts = counts,
  conditions = conditions,
  formulas = formulas,
  formulaIndexes = formulaIndexes,
  groups = fractions
)
```

## Set fitting options

Parameter values are estimated by maximum likelihood method using
L-BFGS-S  optimisation procedure (see help for `optim`).
This function requires to 
define boundaries for possible parameter values and a stopping criteria.
In `pulseR`, the fitting procedure uses relative change in parameter values
between sequential iterations as the stopping rule ("relative tolerance").
Normalisation factors can be recovered only up to a constant multiplicative 
factor.   
By default, the first normalisation factor is always equal 1
(in our case, for the total fraction). However, the user must provide 
formal boundary values for the first factor as well, although
they will be ignored. This is done for the sake of consistency.
```{r }
# lower and upper boundaries for the normalisation factors. 
# The total one will be ignored, because the first coefficient 
# is always the reference one with the value 1. 
# The reason is that we can identify the means of read numbers only
# up to an unknown multiplier.
lbNormFactors <- list(
  total_fraction = 1,
  pull_down      = c(.1,.010),
  flow_through   = c(.1,.010))
ubNormFactors <- list(
  total_fraction = 1,
  pull_down      = c(10, 2),
  flow_through   = c(10, 2))
# set lower and upper boundaries for the rest of the parameters
opts <- setBoundaries(
  list(mu = c(1, 1e6), d = range(par$d) * c(1 / 5, 5)),
  normFactors = list(lbNormFactors, ubNormFactors))
# set the tolerance for the gene-specific parameters and
# the normalisation factors
opts <- setTolerance(params = .01, normFactors = .001, options = opts)

```
## Fit
The L-BFGS-U algorithm requires an initial guess for 
the parameters values.
The outcome of the fitting procedure may depend
on the choice of the initial values.
It is possible to generate random parameter values within the defined boundaries
using the function `initParameters`. The function will generate only 
the parameter values, which were not set in the argument `par`.
Since mean read number and the degradation rate are unique for every gene, 
we also specify it in the argument `geneParams`.
```{r}
# initialise mu and d as gene-specific parameters, i.e. they must
# be sampled for every single gene individually
initPars <- initParameters(par = NULL, geneParams = c("mu", "d"), pd, opts)
str(initPars)
```
Now we are ready to start the fitting:
```{r cache=T}
res <- fitModel(pd, initPars, opts)
```

# Results

## Predictions

The model predictions for the mean read numbers  can be 
estimated using the `predictExpression` function. The plot shows very good 
fit of the model to the count data:
```{r, fig.height=4, fig.width=4}
# get the expected read number for every data point in counts
pr <- predictExpression(pd, res)
plot(x = as.vector(pr$predictions)+.5, y = as.vector(pd$counts)+.5, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "predicted", ylab = "experiment",
     main = "Counts vs. means")
```

## Normalisation factors

The normalisation of the main type of RNA (labelled for the labelled
fraction and unlabelled for the unlabelled) are 
well recovered. However, the factors for the contaminant have a poor 
estimation, since its amount is much lower and estimation of 
its contribution  is much more affected by noise then, see second terms 
in the list of relative errors:
```{r}
str(relist(1 - unlist(res$normFactors) / unlist(normFactors), normFactors))
```
According to the model structure, bias in the estimation of the normalisation
factors affects other model parameters, e.g. the overall degradation rate.
That is why usage of spike-ins can be beneficial, since
it allows to refer to absolute quantities.

## Gene-specific parameters

The estimation of the expression levels are in a good accordance  with the 
true $\mu$ parameter values,
because there are several data points for the total 
fraction, and this fraction represents the very level of the gene expression:
```{r, fig.height=3.4, fig.width=3, fig.show='hold'}
plot(density(1 - res$mu/par$mu), main="rel. err. mu")
plot(x = par$mu, y = res$mu, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "true", ylab = "fitted", main = "mu")
abline(0, 1, col = 3)
```
The estimation of the degradation rate is based on the less number of samples 
(the total fractions provide the information only about the expression level).
Degradation of the unlabelled RNA results in small read counts for the genes, 
hence, in higher noise/signal ratio.
It worsens the quality of the fit for the degradation rate.
That the error is higher for less degrading genes:
```{r, fig.height=4, fig.width=4}
plot(x = par$d, y = res$d, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "true", ylab = "fitted", main = "d")
abline(0, 1, col = 3)
```

However, the error in $d$ for lowly degrading genes (small $d$ values) 
has a minor effect on the mispredictions of the read number, because
$d$ has an exponential impact (e.g. $\mu e^{-dt}$):
```{r, fig.height = 4, fig.width = 4}
plot(x =par$d, y = exp(par$d-res$d),
     pch = 16, cex = .3, log='x',
     xlab = "true d",  
     ylab = expression(exp(d[true]-d[fitted])),
     main = "rel.err in read count prediction")
abline(1, 0, col = 3)
```

That is why the genes with the higher turn-over rate 
have a higher weight during the 
optimisation, and the degradation rate is better recovered.

As mentioned before,  the normalisation of the samples has an impact
on the gene-specific parameters. In our experiment,
the degradation rates are over-estimated for the majority of the genes.
This is counter-balanced by a positive
bias in the normalisation factors estimation
The estimation of $d$
for the less expressed genes are less precise, because the dispersion 
of the negative binomial  random variable increases for
lower means:

```{r, fig.height=4, fig.width=4}

plot(x = par$mu, y = log2(res$d / par$d), 
     pch = 16, cex = .3, log = 'x',
     xlab = "true mu", ylab = "fitted/true", main = "d")
abline(a = 0, b = 0, col = 3)
```

```{r}
summary(res$d/par$d)
```


## Conclusion

Here we presented a validation of the pulseR package performance on 
the simulated data. As a result, we show that the values of
the gene-specific parameters  can be recovered by 
the maximum likelihood estimation  implemented in the package.
The quality of the estimations depends directly on the data, i.e.
on the amount of information and noise in the read numbers.

The pulseR package enables to estimate parameters even  
in the absence of  spike-ins. 
However, this approach is limited to the systems, which 
has structurally and practically identifiable parameters.
The identifiability is defined by the number of replicates, the type of the
fractions provided, the cross-contamination rates and the sequence depth 
(read numbers per feature).