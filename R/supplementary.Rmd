---
title: "Supplementary material"
author: "Alexey Uvarovskii, Christoph Dieterich"
date: '`r Sys.Date()`'
output:
  pdf_document:
    highlight: default
    toc: yes
    toc_depth: 3
  github_document: default
mainfont: Helvetica
fontsize: 12pt
urlcolor: cyan
---

## Introduction

Here we validate performance of the pulseR package on the simulated data.
We consider a pulse-experiment with no spike-ins added.
The data include the total, the pull-out and the flow-through
fractions for four time points in two replicates.

In the pulse-experiment, the unlabelled RNA is being degraded, starting
from the steady-state amount at time $t=0$hr. The labelled fraction is being
synthesised with the rate $s$, and it degrades with the same rate $d$ 
as well.
A system of ordinary differential equations, which describes this processes, is
$$
\begin{aligned}
\frac{d\text{[labelled RNA]}}{dt} &= s - d \text{[labelled RNA]}\\
\frac{d\text{[unlabelled RNA]}}{dt} &= -d \text{[unlabelled RNA]}\\
\text{[total]} &= \text{[labelled]} + \text{[unlabelled]}
\end{aligned}
$$
For constant rates of degradation $d$ and synthesis $s$, the amounts of RNA 
at the time $t$ are
$$ 
\begin{aligned}
 \text{[total RNA]} &= \frac{s}{d} \equiv \mu \\
\text{[labelled RNA]} &= \mu (1 - e^{-dt})  \\
 \text{[unlabelled RNA]} &= \mu e^{-dt}, 
\end{aligned}
$$

where $\mu$ is the expression level of a gene in a steady state.

## Definitions

### Formulas

We can simulate count data using internal pulseR function
`pulseR:::generateTestDataFrom`. For this, one needs to define the formulas
for the mean read number of all three fractions:

```{r}
library(pulseR)

set.seed(259)

nGenes <- 530
nReplicates <- 2
nTime <- 4


formulas <- MeanFormulas(
  total        = mu,
  labelled     = mu * (1 - exp(-d*time)),
  unlabelled   = mu * exp(-d*time)
)
```

### Fractions

In reality, there are no pure labelled or unlabelled fractions in samples.
That is why it may be important to model fraction cross-contamination.
Here we assume that the labelled fraction consists of certain amount of
the unlabelled one, and, vice versa, the unlabelled one is contaminated
with the labelled molecules.
Hence, we distinguish the number of labelled reads and the number of reads
in the "labelled" pull-out fraction.

This definition allows us to calculate mean read number in the 
fractions as a [linear combination](https://en.wikipedia.org/wiki/Linear_combination) of the 
formulas for the labelled and unlabelled RNA amounts:

```{r}
# important: the labels must be the same as in formulas,
# or they must be integer list indexes
formulaIndexes <- list(
  total_sample   = 'total',
  label_sample   = c('labelled', 'unlabelled'),
  unlabel_sample = c('unlabelled', 'labelled')
)
```
### Conditions 

We specify the condition `data.frame`, which includes information about
the type of  sample and its time point:

```{r}
# create nReplicates * nTime * 3 (labelled, unlabelled, total) data points
conditions <- data.frame(
  condition = rep(names(formulaIndexes), each = nTime),
  time      = rep(1:nTime, length(formulaIndexes) * nReplicates))
rownames(conditions) <- paste0("sample_", seq_along(conditions$condition))
knitr::kable(conditions)
```

### Normalisation factors

Since we are going to simulate an experiment without spike-ins, 
one needs to define the relation between different samples via
*normalisation factors*.
We divide samples into groups depending on their time point and fraction.
Except the total fraction, other samples are considered to belong to different
group if the time points are different:
```{r}
fractions <- as.character(interaction(conditions))
# assume that the total RNA amount does not change with the time
# so all total fractions can be treated together
fractions[grep("total", fractions)] <- "total_sample"
knitr::kable(cbind(rownames(conditions),fractions))
```

We use the internal package function  `pulseR:::addKnownToFormulas` in order 
to get the correct form of the list with the normalisation factors.
```{r}
known <- pulseR:::addKnownToFormulas(formulas, formulaIndexes, conditions)
normFactors <- known$formulaIndexes[unique(names(known$formulaIndexes))]
# the total fractions have the reference factor = 1
normFactors <- normFactors[-grep("total", names(normFactors))]
normFactors <- c(list(total_sample = 1), normFactors)
# linear combinations with the coefficient 0.1 for contaminating fraction
# and the coefficient 3 for the main fraction of the sample
normFactors <- relist(c(1, rep(3, length(unlist(normFactors)) - 1)),
                      normFactors)
normFactors[-1] <- lapply(normFactors[-1], '[[<-',2,.10)
str(normFactors)
```

## Simulation
We sample the mean expression level and the degradation rates from 
finite intervals:
```{r}
# set size factor for the rnbinom function
par <- list(size = 1e2)
# set mean read number for every gene 
# by sampling from the log-uniform distribution
par$mu <- exp(runif(nGenes, 0, log(1e5)))
# set the degradation rates from log-uniform distribution
par$d <- exp(runif(nGenes,log(0.01), log(2)))


```
And, finally, we simulate the data from the negative binomial distribution
using the `generateTestDataFrom` function: 
```{r}
# the generateTestDataFrom needs for an input normFactors 
# provided for every individual sample (i.e. we need to utilise 
# the group information ourselves)
allNormFactors <- pulseR:::multiplyList(normFactors, fractions)

counts <- generateTestDataFrom(
  formulas, formulaIndexes, allNormFactors, par, conditions)
```

## Fitting

This section describes a usual workflow for the analysis of the count data
originating from the spike-ins-free experiment  defined above.
This is an entry point of the package application to the real data.

### Create the PulseData object
We define a PulseData object on the basis of the generated read counts,
the condition matrix, relations between formulas and samples.
In addition, we provide the information
how to split the samples during the normalisation.
```{r}
pd <- PulseData(
  counts = counts,
  conditions = conditions,
  formulas = formulas,
  formulaIndexes = formulaIndexes,
  groups = fractions
)
```

### Set fitting options
Before the fitting, one needs to provide
the lower and upper boundaries for the parameters values.
Also we set here the relative tolerance thresholds.
```{r }
# lower and upper boundaries for the normalisation factors. 
# The total one will be ignored, because the first coefficient 
# is always the reference one with the value 1. 
# The reason is that we can identify the means of read numbers only
# up to an unknown multiplier.
lbNormFactors <- list(
  total_sample   = 1,
  label_sample   = c(.1,.010),
  unlabel_sample = c(.1,.010))
ubNormFactors <- list(
  total_sample   = 1,
  label_sample   = c(10, 2),
  unlabel_sample = c(10, 2))
# set lower and upper boundaries for the rest of the parameters
opts <- setBoundaries(
  list(mu = c(1, 1e6), d = range(par$d) * c(1 / 5, 5)),
  normFactors = list(lbNormFactors, ubNormFactors))
# set the tolerance for the gene-specific parameters and
# the normalisation factors
opts <- setTolerance(params = .01, normFactors = .001, options = opts)

```
### Fit
 One needs to provide the first guess of
the parameters values to the fitting function.
The outcome of the fitting procedure may depend
on the choice of the initial values.
```{r}
# initialise mu and d as gene-specific parameters, i.e. they must
# be sampled for every single gene individually
initPars <- initParameters(par = NULL, geneParams = c("mu", "d"), pd, opts)
str(initPars)
```
Now we are ready to start the fitting:
```{r cache=T}
res <- fitModel(pd, initPars, opts)
```

## Results

### Normalisation factors

The normalisation of the main fraction in the samples is 
recovered well (i.e. the coefficient `3`).
```{r}
str(res$normFactors)
```
Since the normalisation factors are affect the mean read number in 
a sample,
they affect the identifiability of the expression levels and the deagradation 
rates.

### Gene-specific parameters

The estimated read mean numbers are well consistent with the 
raw simulated data:
```{r, fig.height=4, fig.width=4}
# get the expected read number for every data point in counts
pr <- predictExpression(pd, res)
plot(x = as.vector(pr$predictions)+.5, y = as.vector(pd$counts)+.5, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "predicted", ylab = "experiment",
     main = "Counts vs. means")
```

Due to high number of total fraction samples, the expression level $\mu$ 
is also well recovered from the data:

```{r, fig.height=3.4, fig.width=3, fig.show='hold'}
plot(density(1 - res$mu/par$mu), main="rel. err. mu")
plot(x = par$mu, y = res$mu, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "true", ylab = "fitted", main = "mu")
abline(0, 1, col = 3)
```
The estimation of the degradation rate is based on the less number of samples 
(the total fractions provide the information only about the expression level).
Hence, the quality of the fit is worse, than for the $\mu$ parameter.
We see that the error is higher for less degrading genes:
```{r, fig.height=4, fig.width=4}
plot(x = par$d, y = res$d, 
     pch = 16, cex = .3, log = 'xy', 
     xlab = "true", ylab = "fitted", main = "d")
abline(0, 1, col = 3)

```

However, the misfit in $d$ for lowly degrading genes 
has a minor effect on the error in predictions of the read number
in comparison to the misfit in the higher ones, because
it has an exponential impact:
```{r, fig.height = 4, fig.width = 4}
plot(x =par$d, y = exp(par$d-res$d),
     pch = 16, cex = .3, 
     xlab = "true", ylab = "fitted", 
     main = expression(exp(d[true]-d[fitted])))
abline(1, 0, col = 3)
```

Hence, the genes with the higher turn-over get a higher weight during 
optimisation of the degradation rate for the case of this simulated data.

As mentioned before,  the normalisation of the samples has an impact
on the gene-specific parameters. In our experiment,
the degradation rates are over-estimated for the majority of the genes.
This is counter-balanced by a positive
bias in the normalisation factors estimation
The estimation of $d$
for the less expressed genes are less precise, because the dispersion 
of the negative binomial  random variable increases for
lower means:

```{r, fig.height=4, fig.width=4}

plot(x = par$mu, y = log2(res$d / par$d), 
     pch = 16, cex = .3, log = 'x',
     xlab = "true mu", ylab = "fitted/true", main = "d")
abline(a = 0, b = 0, col = 3)
```

```{r}
summary(res$d/par$d)
```


## Conclusion

Here we presented a validation of the pulseR package performance on 
the simulated data. As a result, we show that the values of
the gene-specific parameters  can be recovered by 
the maximum likelihood estimation  implemented in the package.
The quality of the estimations depends directly on the data, i.e.
on the amount of information and noise in the read numbers.

The pulseR package enables to estimate parameters even  
in the absence of  spike-ins. 
However, this approach is limited to the systems, which 
has structurally and practically identifiable parameters.
The identifiability is defined by the number of replicates, the type of the
fractions provided, the cross-contamination rates and the sequence depth 
(read numbers per feature).